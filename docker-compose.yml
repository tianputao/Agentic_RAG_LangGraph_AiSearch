# Docker Compose for Agentic RAG System
version: '3.8'

services:
  agentic-rag:
    build: .
    ports:
      - "8501:8501"
    environment:
      # Azure OpenAI Configuration
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_KEY=${AZURE_OPENAI_KEY}
      - AZURE_OPENAI_CHAT_DEPLOYMENT=${AZURE_OPENAI_CHAT_DEPLOYMENT}
      - AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=${AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2024-02-15-preview}
      
      # Azure AI Search Configuration
      - AZURE_SEARCH_ENDPOINT=${AZURE_SEARCH_ENDPOINT}
      - AZURE_SEARCH_KEY=${AZURE_SEARCH_KEY}
      - AZURE_SEARCH_INDEX_NAME=${AZURE_SEARCH_INDEX_NAME}
      - AZURE_SEARCH_API_VERSION=${AZURE_SEARCH_API_VERSION:-2023-11-01}
      
      # Application Configuration
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - MAX_SEARCH_RESULTS=${MAX_SEARCH_RESULTS:-20}
      - MAX_CONCURRENT_SEARCHES=${MAX_CONCURRENT_SEARCHES:-5}
      - ENABLE_CONVERSATION_MEMORY=${ENABLE_CONVERSATION_MEMORY:-true}

      # Citation URL
      - DOC_BASEURL=${DOC_BASEURL}
      - DOC_SAS=${DOC_SAS}
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
  # Optional: Redis for caching (future enhancement)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    profiles:
      - with-cache

volumes:
  redis_data:
